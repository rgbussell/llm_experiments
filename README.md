# llm_experiments
Experiments with large language models

# Goals
1. set up a cli interface for local run of an llm
2. set up a python api call to local llm mode

# options for setting up local models:
lmstudio: GUI based
ollama: cli based

# setting up lm studio
lmstudio.ai -- Linux download is available

# ollama commands
ollamma run ollama2
ollamma list # list the models installed currently
ollama serve # start the service

# olllama api
installing ollama exposes an http api so we can all it